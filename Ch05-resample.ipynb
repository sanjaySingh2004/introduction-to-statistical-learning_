{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9842bd6-76b3-4207-9781-8e2be1a528e7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Cross-Validation and the Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5233c7d-2d13-429d-83a0-f260908b2fac",
   "metadata": {},
   "source": [
    "resampling techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6b0f21f-1293-4e15-9ce0-387a497ff67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from ISLP import load_data\n",
    "from ISLP.models import (ModelSpec as MS,\n",
    "                         summarize,\n",
    "                         poly)\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ac8db26-0bbd-4e58-89ff-df87746cb9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from sklearn.model_selection import \\\n",
    "     (cross_validate,\n",
    "      KFold,\n",
    "      ShuffleSplit)\n",
    "from sklearn.base import clone\n",
    "from ISLP.models import sklearn_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24089110-28c1-48b5-996b-5cfdc5f119c6",
   "metadata": {},
   "source": [
    "### Validation set Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742954e8-557a-4d3e-8e67-443de20f4647",
   "metadata": {},
   "source": [
    "We use the validation set approach in order to estimate the test error rates thatresult from fitting various linear models on the Auto data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82dff954-0c50-4ff2-8972-7610a0907f7c",
   "metadata": {},
   "source": [
    "Here we use test_train_split() function to split the data into training and vaidation sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96aa361b-6774-4733-bb37-0fd510dae35d",
   "metadata": {},
   "source": [
    "We be using random seed to deal with random elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c687c96f-102b-4f99-a9b0-51381204f5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "Auto = load_data('Auto')\n",
    "Auto_train, Auto_valid = train_test_split(Auto,\n",
    "                                         test_size=196,\n",
    "                                         random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b720658c-d8b2-4430-b4f4-28661c47598f",
   "metadata": {},
   "source": [
    "There are 392 obervation in this data set we use train test split to split them equally of size 196 using test_size=196"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77053e2e-e30f-4c4e-8b02-9163492f789e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_mm = MS(['horsepower'])\n",
    "X_train = hp_mm.fit_transform(Auto_train)\n",
    "y_train = Auto_train['mpg']\n",
    "model = sm.OLS(y_train, X_train)\n",
    "results = model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24ecd05-01c3-420e-89ce-ab370b572ba6",
   "metadata": {},
   "source": [
    "with Auto_train we will fit a linear regression using only the obervations corresponding to the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "251898b1-da70-4b27-9448-4ca4b35f8999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.61661706966988"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid = hp_mm.transform(Auto_valid)\n",
    "y_valid = Auto_valid['mpg']\n",
    "valid_pred = results.predict(X_valid)\n",
    "np.mean((y_valid - valid_pred)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ce2bef-e768-4fd1-ac31-e0345713a142",
   "metadata": {},
   "source": [
    "There is a method of results i.e predict() which is used to evaluate on the model matrix for this model created using the validation data set. we have also calculated the MSE of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5fd664-8e31-42a2-93c9-3f8003277e9f",
   "metadata": {},
   "source": [
    "Here validation dataset is used for hyperparameter tuning. for checking overfitting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "de6b7832-9818-41ad-ac71-297362809bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalMSE(terms,\n",
    "            response,\n",
    "            train,\n",
    "            test):\n",
    "\n",
    "   mm = MS(terms)\n",
    "   X_train = mm.fit_transform(train)\n",
    "   y_train = train[response]\n",
    "\n",
    "   X_test = mm.transform(test)\n",
    "   y_test = test[response]\n",
    "\n",
    "   results = sm.OLS(y_train, X_train).fit()\n",
    "   test_pred = results.predict(X_test)\n",
    "\n",
    "   return np.mean((y_test - test_pred)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e136898-4af3-495c-9619-aa3eda4991a3",
   "metadata": {},
   "source": [
    "we provide a function evalMSE() that takes a model string as well as a training and test set and returns the MSE on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f8ff87e2-f1e4-4775-aab0-4acc7c620bd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23.61661707, 18.76303135, 18.79694163])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE = np.zeros(3)\n",
    "for idx, degree in enumerate(range(1, 4)):\n",
    "    MSE[idx] = evalMSE([poly('horsepower', degree)],\n",
    "                       'mpg',\n",
    "                       Auto_train,\n",
    "                       Auto_valid)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e64f91-b8b0-4d38-a381-475aee641f24",
   "metadata": {},
   "source": [
    "we use enumerate() function here to estimate the validation MSE using linear, Quadratic and cubic fits. It will give both the values and indices of objects as one iterates over a for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "87450808-a8d7-4094-b857-c9897ec915a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20.75540796, 16.94510676, 16.97437833])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Auto_train, Auto_valid = train_test_split(Auto,\n",
    "                                          test_size=196,\n",
    "                                          random_state=3)\n",
    "MSE = np.zeros(3)\n",
    "for idx, degree in enumerate(range(1, 4)):\n",
    "    MSE[idx] = evalMSE([poly('horsepower', degree)],\n",
    "                       'mpg',\n",
    "                       Auto_train,\n",
    "                       Auto_valid)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35931107-5aed-4be0-bf75-b1d15b50b4c0",
   "metadata": {},
   "source": [
    "using this split of observations into a training set and a validation set, we find that the validation set error rates for the models with linar, quadratic and cubic terms are 20.76, 16.95, 16.97. These results are cosistent with the previous findings thata model that predicts `mpg` using a quadratic function of `horsepower` performs better than a model that involves only a linear function of horsepower and there is no evidence of an improvement in using a cubic fucntion of horsepower."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe58483-f88e-4255-a18a-ac25c5c7c010",
   "metadata": {},
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d1fa95-0174-46c5-9bd5-751308f791a8",
   "metadata": {},
   "source": [
    "Cross-validation helps check how well a model works. In Python, it’s easiest to do this using sklearn. But if you build your model using statsmodels, it won’t work directly with sklearn. To fix this, we use a `wrapper` called sklearn_sm() from the ISLP package. This wrapper connects statsmodels models with sklearn tools. You can also give it extra info like the formula and model settings. This makes cross-validation simple, even for statsmodels models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "24d3f4b4-332d-415e-99fa-3a642ac73833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.231513517929226"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_model = sklearn_sm(sm.OLS,\n",
    "                      MS(['horsepower']))\n",
    "X, Y = Auto.drop(columns=['mpg']), Auto['mpg']\n",
    "cv_results = cross_validate(hp_model,\n",
    "                            X,\n",
    "                            Y,\n",
    "                            cv=Auto.shape[0])\n",
    "cv_err = np.mean(cv_results['test_score'])\n",
    "cv_err"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732e4bc9-0b73-45e1-863b-91d4e993446e",
   "metadata": {},
   "source": [
    "The cross_validate() function in sklearn needs a model (with fit(), predict(), and score() methods), feature data X, and response Y. If we set the cv argument to a number K, it does *K-fold cross-validation. If we set it equal to the total number of observations, it performs **leave-one-out cross-validation (LOOCV). This function returns a dictionary, but we only need the test score (MSE), which in one case is 24.23. We can repeat this for more complex models. To do this automatically, we use a for loop that fits **polynomial models from degree 1 to 5*, calculates the cross-validation error, and saves each result in a list called cv_error. The variable d in the loop is the polynomial degree. Running this might take a few seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "be31a335-ec2b-4281-b48a-d2c3da73e2d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24.23151352, 19.24821312, 19.33498406, 19.42443033, 19.03324353])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_error = np.zeros(5)\n",
    "H = np.array(Auto['horsepower'])\n",
    "M = sklearn_sm(sm.OLS)\n",
    "for i, d in enumerate(range(1,6)):\n",
    "    X = np.power.outer(H, np.arange(d+1))\n",
    "    M_CV = cross_validate(M,\n",
    "                          X,\n",
    "                          Y,\n",
    "                          cv=Auto.shape[0])\n",
    "    cv_error[i] = np.mean(M_CV['test_score'])\n",
    "cv_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1d41b7-99f0-4cc4-b2ef-1d109caa4727",
   "metadata": {},
   "source": [
    "outer() method of the np.power() function. The outer() method is applied to an operation that has two arguements (add(), min(), or power()). it has two arrays as arguements and then forms a larger array where the operation is applied to each pair of elements of the two arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "87bd7640-0d36-4785-a48a-a66a6ebf4ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5,  7],\n",
       "       [ 7,  9],\n",
       "       [11, 13]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([3, 5, 9])\n",
    "B = np.array([2, 4])\n",
    "np.add.outer(A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82b1cbb-a081-4d6a-93e9-e7b8209116e4",
   "metadata": {},
   "source": [
    "In the CV example above, we used K = n, but of course we can also use K < n. The code in very similar to the above(and is significantly faster). Here we use KFold() to partition the data into K = 10 random_state to set a random seed and initialize a vector cv_error in which we will store the CV errors corresponding to the polynomial fits of degrees one to five."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f624074f-d144-431e-bf4d-fa8d81056410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24.20766449, 19.18533142, 19.27626666, 19.47848399, 19.13719696])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_error = np.zeros(5)\n",
    "cv = KFold(n_splits=10,\n",
    "           shuffle=True,\n",
    "           random_state=0) # use same splits for each degree\n",
    "for i, d in enumerate(range(1,6)):\n",
    "    X = np.power.outer(H, np.arange(d+1))\n",
    "    M_CV = cross_validate(M,\n",
    "                          X,\n",
    "                          Y,\n",
    "                          cv=cv)\n",
    "    cv_error[i] = np.mean(M_CV['test_score'])\n",
    "cv_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1807eb-c15f-46e9-875e-6e9c614bcd09",
   "metadata": {},
   "source": [
    "LOOCV (Leave-One-Out CV) should be faster for linear models because it has a shortcut formula, but cross_validate() doesn't use that formula—so it's slower in practice.\n",
    "\n",
    "We also see that using cubic or higher-degree polynomials doesn't improve test error much compared to a simple quadratic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0cdba462-2c77-4139-9c7a-2d7f056d7b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23.61661707])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation = ShuffleSplit(n_splits=1,\n",
    "                          test_size=196,\n",
    "                          random_state=0)\n",
    "results = cross_validate(hp_model,\n",
    "                         Auto.drop(['mpg'], axis=1),\n",
    "                         Auto['mpg'],\n",
    "                         cv=validation);\n",
    "results['test_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bf86e2-01d9-4a85-8fef-835774fcef24",
   "metadata": {},
   "source": [
    "The cross_validate() function is flexible—you can use it with different data splitting methods like ShuffleSplit() to easily try the validation set approach instead of K-fold.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c52bfda7-053f-49a7-a426-25bd0720df9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23.802232661034164, 1.421845094109187)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation = ShuffleSplit(n_splits=10,\n",
    "                          test_size=196,\n",
    "                          random_state=0)\n",
    "results = cross_validate(hp_model,\n",
    "                         Auto.drop(['mpg'], axis=1),\n",
    "                         Auto['mpg'],\n",
    "                         cv=validation)\n",
    "results['test_score'].mean(), results['test_score'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c2c19b-aba8-4b0d-bebe-6244c82ba137",
   "metadata": {},
   "source": [
    "One can estimate the variability in the test error by running this. this standard deviation is not a valid estimate of the sampling vairability of the mean test score or the individual scores, since the randomly- selected training samples overlap and hence introduce correlations. but it does give an idea of the monte carlo variation incurred by picking different random folds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf1d14e-519a-4776-90f4-2b9380cbd84f",
   "metadata": {},
   "source": [
    "### Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95638dc-4c56-43f8-b2f7-3225408ef6ad",
   "metadata": {},
   "source": [
    "The bootstrap is a very useful technique in statistics for estimating the accuracy of a statistic, such as its standard error or variance. One big advantage of the bootstrap is that it works in almost any situation and doesn't require complex mathematical formulas. Instead, it relies on resampling from the data to assess how a statistic might vary if we were to repeat the experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2956b2-34cd-48f5-bc05-5ebb1a3d1a91",
   "metadata": {},
   "source": [
    "### Estimating the Accuracy of a satistic of Interest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac23aef4-0eb7-4cab-98e7-db12de93ab1b",
   "metadata": {},
   "source": [
    "To perform the bootstrap, we repeatedly draw random samples with replacement from our dataset. For each resample, we calculate the statistic of interest. After many such resamples, we look at the variation in those statistics—this gives us an estimate of the standard error.\n",
    "\n",
    "In Python, even though there are built-in functions for the bootstrap, it's simple enough that we can write our own. For example, suppose we want to estimate the variability of a parameter (like α) based on a dataset that has columns X and Y. We can create a function called alpha_func() that takes a DataFrame and a set of row indices, and returns the estimated value of α using only the selected rows.\n",
    "\n",
    "This custom function can then be used repeatedly in a bootstrap loop to compute α on many resampled datasets, allowing us to estimate how much α might vary across different samples. This illustrates how flexible and practical the bootstrap method is in real-world data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "96c3565c-2a5f-4cc5-ac30-a73121ef91cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Portfolio = load_data('Portfolio')\n",
    "def alpha_func(D, idx):\n",
    "   cov_ = np.cov(D[['X','Y']].loc[idx], rowvar=False)\n",
    "   return ((cov_[1,1] - cov_[0,1]) /\n",
    "           (cov_[0,0]+cov_[1,1]-2*cov_[0,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf0d1f2-96e2-4a87-b252-5c05c3b7aa86",
   "metadata": {},
   "source": [
    "This fuction returns an estimate for alpha base on applying the minimum variance formula to the observations indexed by the arguement `idx`. It simply estimates aplha using all 100 observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0ad2cb6e-0934-417f-b0f4-58238f18f4c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5758320745928298"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_func(Portfolio, range(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333f4dc1-476c-4e3e-a96f-fa2df159cf22",
   "metadata": {},
   "source": [
    "Next we randomly select 100 obervations from range(100), with replacement. Constructing a new bootstrap data set and recomputing aplha head based on the new data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e9224826-6022-47e3-ba29-3d02d139074c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6074452469619002"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.default_rng(0)\n",
    "alpha_func(Portfolio,\n",
    "           rng.choice(100,\n",
    "                      100,\n",
    "                      replace=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be59508f-22cf-42d4-87c0-4c26d8eafa6e",
   "metadata": {},
   "source": [
    "This process can be generalized to create a simple function boot_SE() for computing the bootstrap standard error for arbitrary functions that take only a data frame as an arguement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "60b8a197-9e3f-4ba6-bad5-2b00ab5dca47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boot_SE(func,\n",
    "            D,\n",
    "            n=None,\n",
    "            B=1000,\n",
    "            seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    first_, second_ = 0, 0\n",
    "    n = n or D.shape[0]\n",
    "    for _ in range(B):\n",
    "        idx = rng.choice(D.index,\n",
    "                         n,\n",
    "                         replace=True)\n",
    "        value = func(D, idx)\n",
    "        first_ += value\n",
    "        second_ += value**2\n",
    "    return np.sqrt(second_ / B - (first_ / B)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456fd218-f04b-488a-9905-119fb8dee271",
   "metadata": {},
   "source": [
    "The use of `_` as a loop variable in `for _ in range(8)`. This is often used if the value of the counter is unimportand and simply makes sure the loop is executed `B` times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7f778c73-02b3-46e7-b9fb-0d4aa84e6f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09118176521277577"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_SE = boot_SE(alpha_func,\n",
    "                   Portfolio,\n",
    "                   B=1000,\n",
    "                   seed=0)\n",
    "alpha_SE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb507ca5-5f01-4639-816a-ee37fa7cd6e0",
   "metadata": {},
   "source": [
    "lets use our function to evaluate the accuracy of our estimate of alpha using B = 1,000 bootstrap replications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f702a91-94f3-4c0b-9a30-14b284acc002",
   "metadata": {},
   "source": [
    "The final output shows that the bootstrap estimate for SE(alpha head) is 0.0912"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4a3a04-366f-457c-b6ad-316a3d6efa55",
   "metadata": {},
   "source": [
    "### Estimating the Accuracy of a Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43afa77-cddc-484b-9106-0541c8a38b59",
   "metadata": {},
   "source": [
    "The bootstrap can be used to measure how much the coefficients and predictions from a model might vary. In this example, we apply it to a linear regression model that predicts mpg from horsepower using the Auto dataset. We'll check the variability of the intercept and slope estimates and compare the bootstrap results to those from standard formulas.\n",
    "\n",
    "To do this, we use a custom boot_SE() function, which needs a function that takes a DataFrame D and row indices idx. Since we're bootstrapping a specific regression model, we write a general-purpose function boot_OLS() that takes a model formula and uses the data to refit the model on each bootstrap sample.\n",
    "\n",
    "We also use the clone() function to ensure any derived features (like from poly()) are recomputed for each resample. This helps us get more accurate estimates of model variability using the bootstrap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0dad2182-0b02-4a1a-ab22-6818d7d4f453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boot_OLS(model_matrix, response, D, idx):\n",
    "    D_ = D.loc[idx]\n",
    "    Y_ = D_[response]\n",
    "    X_ = clone(model_matrix).fit_transform(D_)\n",
    "    return sm.OLS(Y_, X_).fit().params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01c6a01-1388-408a-b27d-c4ad6dd337cb",
   "metadata": {},
   "source": [
    "This is not quite what is needed as the first argument to boot_SE(). The first two arguments which specify the model will not change in the bootstrap process, and we wouuld like to freeze them. The function `partial()` from `functools` module does precisely this: it takes a function as an arguement, and freezes some of its arguements, strating from the left. We use it to freeze the first two model-formula arguments of boot_OLS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "50c3d63c-cdc5-4932-ae61-efad2dcbc432",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_func = partial(boot_OLS, MS(['horsepower']), 'mpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e83b78-163f-47c0-ba41-1aeeade0d66f",
   "metadata": {},
   "source": [
    "hp_func will show that it has two arguments D and idx it is a version of boot_OLS() with the first two arguments frozen and hence is ideal as the first arugment for boot_SE()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "add3ae12-766f-4378-bd2e-f0ffa55fe8ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[39.12226577, -0.1555926 ],\n",
       "       [37.18648613, -0.13915813],\n",
       "       [37.46989244, -0.14112749],\n",
       "       [38.56723252, -0.14830116],\n",
       "       [38.95495707, -0.15315141],\n",
       "       [39.12563927, -0.15261044],\n",
       "       [38.45763251, -0.14767251],\n",
       "       [38.43372587, -0.15019447],\n",
       "       [37.87581142, -0.1409544 ],\n",
       "       [37.95949036, -0.1451333 ]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.default_rng(0)\n",
    "np.array([hp_func(Auto,\n",
    "          rng.choice(Auto.index,\n",
    "                     392,\n",
    "                     replace=True)) for _ in range(10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0f8f5a-ecd6-47f9-885f-48f12bc7717d",
   "metadata": {},
   "source": [
    "hp_func() function can now be used in order to create bootstrap estimates for the intercept and slope terms by randomly sampling from among the observations with replacement. We first demostrate its utility on 10 bootstrap samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0f7506c4-5300-45a3-921b-5e4aa6f1ed81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intercept     0.731176\n",
       "horsepower    0.006092\n",
       "dtype: float64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_se = boot_SE(hp_func,\n",
    "                Auto,\n",
    "                B=1000,\n",
    "                seed=10)\n",
    "hp_se"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3e5dbe-b1b9-4570-bb22-e4a8d01224be",
   "metadata": {},
   "source": [
    "We use the boot_SE() function to compute the standard errors of 1000 bootstrap estimates for the intercept and slope terms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e41414d-5eb7-441d-88b7-916c5ae588c4",
   "metadata": {},
   "source": [
    "The bootstrap estimates the intercept as 0.85 and the slope as 0.0074. These values show the typical variation we might expect if we repeated the sampling. As mentioned earlier, we can also calculate standard errors for regression coefficients using standard formulas. These can be easily obtained using the summarize() function from ISLP.sm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ad7f1653-95e0-4580-b040-da5c5d5c4211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intercept     0.717\n",
       "horsepower    0.006\n",
       "Name: std err, dtype: float64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_model.fit(Auto, Auto['mpg'])\n",
    "model_se = summarize(hp_model.results_)['std err']\n",
    "model_se"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a9b96d-a1cb-4b95-8add-78c55334ff92",
   "metadata": {},
   "source": [
    "The standard error estimates from formulas are 0.717 for the intercept and 0.006 for the slope. These are a bit different from the bootstrap results (0.85 and 0.0074), but that’s not a problem—in fact, it highlights a key strength of the bootstrap.\n",
    "\n",
    "Standard formulas assume certain things, like a correct linear model and fixed predictor values. They also estimate noise (σ²) using residuals, which can be inflated if the true relationship is non-linear, as seen in the data.\n",
    "\n",
    "The bootstrap, however, does not rely on these assumptions, so it's often more realistic and accurate, especially when the model is misspecified.\n",
    "\n",
    "When we fit a quadratic model (which better fits the data), the bootstrap and formula-based estimates for standard errors match more closely, showing improved agreement when the model is more appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7e5c3d0f-9b2a-4007-93da-d6ae8086ad5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intercept                                  1.538641\n",
       "poly(horsepower, degree=2, raw=True)[0]    0.024696\n",
       "poly(horsepower, degree=2, raw=True)[1]    0.000090\n",
       "dtype: float64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quad_model = MS([poly('horsepower', 2, raw=True)])\n",
    "quad_func = partial(boot_OLS,\n",
    "                    quad_model,\n",
    "                    'mpg')\n",
    "boot_SE(quad_func, Auto, B=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9077b89a-d770-4f0a-9903-b8429dde1383",
   "metadata": {},
   "source": [
    "We now compute the bootstrap standard errors and compare them with the standard regression estimates after fitting a quadratic model to the data. Since this model fits the data better the bootstrap and formual- based estimates for the intercept, slope and quadratic term are now more similar. This shows that when the model fits well both methods give consistent results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0ac9f779-e6f2-4631-927a-52b24c72cc80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intercept                                  1.800\n",
       "poly(horsepower, degree=2, raw=True)[0]    0.031\n",
       "poly(horsepower, degree=2, raw=True)[1]    0.000\n",
       "Name: std err, dtype: float64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = sm.OLS(Auto['mpg'],\n",
    "           quad_model.fit_transform(Auto))\n",
    "summarize(M.fit())['std err']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28a1e02-6a9b-45ff-893d-18e2859cd900",
   "metadata": {},
   "source": [
    "We compare the results to the standard errors computed using sm.OLS()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf54462-34d7-4a6c-b24d-9da488c9bd33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
